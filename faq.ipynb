{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMEhm42YagGDsBX9Tbtp33",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oldper/LLM/blob/main/faq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyNrtdh645y0"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "model = BertModel.from_pretrained('bert-base-chinese', num_labels=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9QInvmq46JP",
        "outputId": "49a89d7b-b4f9-4c21-89cd-1695d2991353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_question(question):\n",
        "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
      ],
      "metadata": {
        "id": "Z5XD1Ov147wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_question, source, data):\n",
        "  source_vectors = {}\n",
        "  source = [str(s) for s in source]\n",
        "  for id in source:\n",
        "      if id in data:\n",
        "          source_vectors[id] = [encode_question(item['question']) for item in data[id]]\n",
        "  input_vector = encode_question(input_question)\n",
        "\n",
        "  most_similar_question = None\n",
        "  most_similar_id = None\n",
        "  highest_similarity = -1\n",
        "\n",
        "  for id, vectors in source_vectors.items():\n",
        "    for vector, item in zip(vectors, data[id]):\n",
        "      question = item['question']\n",
        "      score = cosine_similarity([input_vector], [vector])[0][0]\n",
        "      if score > highest_similarity:\n",
        "          highest_similarity = score\n",
        "          most_similar_question = question\n",
        "          most_similar_id = id\n",
        "\n",
        "  return most_similar_id\n"
      ],
      "metadata": {
        "id": "szb8WR37BL4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tqdm\n",
        "with open('pid_map_content.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "with open('questions_example.json', 'r') as f:\n",
        "  questions = json.load(f)\n",
        "\n",
        "arr = []\n",
        "for q in questions['questions']:\n",
        "  if q['category'] == 'faq':\n",
        "    arr.append(predict(q['query'], q['source'], data))\n"
      ],
      "metadata": {
        "id": "Y96c4RfE49hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ground_truths_example.json', 'r') as f:\n",
        "  gt = json.load(f)\n",
        "\n",
        "ans_arr = []\n",
        "for ans in gt['ground_truths']:\n",
        "  if ans['category'] == 'faq':\n",
        "    ans_arr.append(ans['retrieve'])\n",
        "\n",
        "ans_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGanjpwIHFrx",
        "outputId": "4cfc9c10-6f6b-48b6-b1f8-bbe1ee4829ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[558,\n",
              " 104,\n",
              " 63,\n",
              " 15,\n",
              " 294,\n",
              " 224,\n",
              " 540,\n",
              " 105,\n",
              " 283,\n",
              " 611,\n",
              " 76,\n",
              " 403,\n",
              " 509,\n",
              " 279,\n",
              " 54,\n",
              " 4,\n",
              " 92,\n",
              " 554,\n",
              " 610,\n",
              " 20,\n",
              " 414,\n",
              " 415,\n",
              " 527,\n",
              " 14,\n",
              " 604,\n",
              " 1,\n",
              " 365,\n",
              " 436,\n",
              " 283,\n",
              " 5,\n",
              " 600,\n",
              " 334,\n",
              " 243,\n",
              " 328,\n",
              " 28,\n",
              " 504,\n",
              " 359,\n",
              " 339,\n",
              " 194,\n",
              " 141,\n",
              " 410,\n",
              " 173,\n",
              " 144,\n",
              " 225,\n",
              " 564,\n",
              " 0,\n",
              " 87,\n",
              " 242,\n",
              " 441,\n",
              " 221]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "arr = [int(a) for a in arr]\n",
        "for i in range(len(arr)):\n",
        "  if arr[i] == ans_arr[i]:\n",
        "    c+=1\n",
        "  else:\n",
        "    print(i)\n",
        "\n",
        "print(\"Accuracy: \", c/len(arr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHnS6M_2JMst",
        "outputId": "bc1f462c-a98d-4380-9fce-81ae9fd19d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "34\n",
            "Accuracy:  0.96\n"
          ]
        }
      ]
    }
  ]
}